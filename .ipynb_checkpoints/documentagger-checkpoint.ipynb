{
 "metadata": {
  "name": "",
  "signature": "sha256:372a09e210e92ffb33f9e7f02a5e9b9d56598077f26dbb4791a837410d026f56"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Multi-Label Document Classification\n",
      "\n",
      "This project aims to use 60 documents to create a multi-label classification system, with entity extraction as a fringe benefit. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import re\n",
      "import os\n",
      "import codecs\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata = pd.read_csv(\"DocumentTagResults.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 289,
       "text": [
        "Index([u'DocumentID', u'Subject', u'FileName', u'TagName'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata['FileName'] = metadata['FileName'].replace(to_replace='.docx', value='.htm', regex=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 290
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filenames = os.listdir('/Users/brandomr/Sites/docs')\n",
      "#gets list of filenames in the document directory\n",
      "\n",
      "len(filenames)\n",
      "#tests how many files are in the docs folder\n",
      "\n",
      "filenames = sorted(filenames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metadata = metadata.sort(columns = 'FileName')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is a quick check on how many tags each document has\n",
      "numbertags = metadata.pivot_table(values='DocumentID', rows=['FileName'], aggfunc = len)\n",
      "\n",
      "print 'Per document the'\n",
      "print 'max number of tags is ' + str(numbertags.max())\n",
      "print 'min number of tags is ' + str(numbertags.min())\n",
      "print 'mean number of tags is ' + str(numbertags.mean())\n",
      "print 'median number of tags is ' + str(numbertags.median())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Per document the\n",
        "max number of tags is 46\n",
        "min number of tags is 2\n",
        "mean number of tags is 11.9242424242\n",
        "median number of tags is 11.0\n"
       ]
      }
     ],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#creates list of tuples for document tags\n",
      "taglist = []\n",
      "for i in range(len(filenames)):\n",
      "    doctags = metadata[metadata['FileName'] == filenames[i]]['TagName'].tolist()\n",
      "    doctags = sorted(doctags)\n",
      "    taglist.append(doctags)\n",
      "\n",
      "#this function pulls a random subset from a list\n",
      "def random_subset(iterator, k):\n",
      "    result = []\n",
      "    n = 0\n",
      "    \n",
      "    for item in iterator:\n",
      "        n +=1\n",
      "        if len(result) < k:\n",
      "            result.append(item)\n",
      "        else:\n",
      "            s = int(random.random()*n)\n",
      "            if s < k: \n",
      "                result[s] = item\n",
      "    \n",
      "    return result\n",
      "\n",
      "#the below code pulls 2 random tags and from the tag list per document    \n",
      "#taglist_reduced = []\n",
      "#for i in range(len(taglist)):\n",
      "#    tagitem = random_subset(taglist[i],2)\n",
      "#    taglist_reduced.append(tagitem)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "taglist_reduced[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 306,
       "text": [
        "[['Public Diplomacy', 'Human Rights'],\n",
        " ['Sustainable Development', 'Oceans & Environment'],\n",
        " ['Whole of Government', 'Legal & Treaty Issues'],\n",
        " ['Whole of Government', 'Legal & Treaty Issues'],\n",
        " ['Public-Private Partnerships', 'Legal & Treaty Issues'],\n",
        " ['Climate Change', 'Congressional Relations'],\n",
        " ['Human Rights', 'Foreign Trade'],\n",
        " ['Foreign Trade', 'Sustainable Development'],\n",
        " ['East Asia & Pacific', 'Budget & Financial'],\n",
        " ['Economic Conditions', 'Foreign Trade']]"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpora = []\n",
      "\n",
      "for i in filenames:\n",
      "    doc = open('/Users/brandomr/Sites/docs/'+ i)\n",
      "    text = doc.read()\n",
      "    #grabs the document as variable text\n",
      "    \n",
      "    text = nltk.clean_html(text)\n",
      "    #strips html formatting\n",
      "    \n",
      "    text = text.replace('&#xa0;', '\\xA0')\n",
      "    text = text.decode('utf-8', 'ignore')\n",
      "    #gets rid of non-break space html and converts to unicode\n",
      "    \n",
      "    corpora.append(text)\n",
      "    #adds to corpora"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tokenizes and chunks for entity extraction\n",
      "def extract_entities(text):\n",
      "    entities = []\n",
      "    for sentence in nltk.sent_tokenize(text):\n",
      "        #tokenizes into sentence\n",
      "        \n",
      "        chunks = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
      "        #tokenizes into words, then tags by parts of speech, then uses nltk's built in chunker\n",
      "        \n",
      "        entities.extend([chunk for chunk in chunks if hasattr(chunk, 'node')])\n",
      "        #iterates through the text and pulls any chunks that are nodes--these are the entities\n",
      "        \n",
      "    return entities\n",
      "\n",
      "#function takes two arguments, a list and the item you want entities for in that list. For example, with this corpora, select a given\n",
      "#item i for analysis--in this case i is just a document in the doc library already brought in\n",
      "def get_entitylist(list, i):\n",
      "    entitylist = []\n",
      "    for entity in extract_entities(list[i]):\n",
      "        #calls extract_entities on the given text\n",
      "        item = '[' + entity.node + '] ' + ' '.join(c[0] for c in entity.leaves())\n",
      "        #gets the entity node type and joins it with the leaf--basically the entity name in this case\n",
      "        entitylist.append(item)\n",
      "        #appends to the entitylist object\n",
      "    return entitylist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#uniq is a function to return only unique items for a given list\n",
      "def uniq(input):\n",
      "    output = []\n",
      "    for x in input: \n",
      "        if x not in output:\n",
      "            output.append(x)\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prints each item in a list on it's own line\n",
      "def printbyline(list):\n",
      "    for item in list:\n",
      "        print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#just a test of the entity extraction tool\n",
      "entitysample = uniq(get_entitylist(corpora, 1))\n",
      "\n",
      "printbyline(sorted(entitysample[:10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[GPE] United States\n",
        "[ORGANIZATION] SSECC Policy Overview\n",
        "[ORGANIZATION] Special Envoy\n",
        "[ORGANIZATION] U\n",
        "[ORGANIZATION] UN Framework Convention\n",
        "[ORGANIZATION] UNFCCC\n",
        "[PERSON] Climate Change\n",
        "[PERSON] Obama\n",
        "[PERSON] Policy Overview\n",
        "[PERSON] Todd Stern\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#converts corpora from a list into a list of tuples where each tuple is the text of the document\n",
      "i=0\n",
      "corpora_processing = []\n",
      "while i < len(corpora):\n",
      "    corpora_processing.append(corpora[i:i+1])\n",
      "    i += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 304
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "\n",
      "\n",
      "#The classification function\n",
      "Below, I specify the parameters of the classification function and use it on a training set: the first 50 documents in the corpus. I use the last 10 documents in the corpus as a test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "\n",
      "x_train = np.array(corpora[:50])\n",
      "y_train = taglist[:50]\n",
      "\n",
      "x_test = np.array(corpora[50:60])\n",
      "y_test = taglist[50:60]\n",
      "\n",
      "classifier = Pipeline([\n",
      "    ('vectorizer', CountVectorizer(ngram_range=(3, 3), stop_words='english', min_df=0.1, max_df=0.75, max_features=500)),\n",
      "    ('tfidf', TfidfTransformer()),\n",
      "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
      "classifier.fit(x_train, y_train)\n",
      "predicted = classifier.predict(x_test)\n",
      "\n",
      "print predicted\n",
      "len(predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Public Affairs', 'Public Diplomacy', 'Youth Issues'), ('Administration', 'Budget & Financial', 'Buildings & Facilities', 'Congressional Relations', 'Department Security', 'Inspector General', 'Strategic & Budget Planning'), ('Public Affairs', 'Public Diplomacy', 'Youth Issues'), ('records management',), ('Public Affairs', 'Public Diplomacy', 'Youth Issues'), ('Administration', 'Budget & Financial', 'Buildings & Facilities', 'Department Security', 'Equipping our People', 'Strategic & Budget Planning'), ('Public Affairs', 'Public Diplomacy', 'Youth Issues'), ('Commercial Advocacy', 'East Asia & Pacific', 'Finance & Monetary', 'Foreign Trade', \"Int'l Information Programs\", 'Investment', 'Middle East & North Africa', \"Other Int'l Organization\", 'QDDR', 'Strategic & Budget Planning', 'Whole of Government'), (\"Int'l Information Programs\", 'QDDR', 'Strategic & Budget Planning', \"Women's Issues\", 'Youth Issues'), ('Public Affairs', 'Public Diplomacy', 'Youth Issues')]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 358,
       "text": [
        "10"
       ]
      }
     ],
     "prompt_number": 358
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(predicted)):\n",
      "    print 'Predicted: ' + str(predicted[i])\n",
      "    print 'Actual: ' +str(y_test[i])\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicted: ('Public Affairs', 'Public Diplomacy', 'Youth Issues')\n",
        "Actual: ['Commercial & Economic Diplomacy', 'Democratization', 'Public-Private Partnerships', 'Public-Private Partnerships', 'Science & Tech Policy', 'Visas', \"Women's Issues\"]\n",
        "\n",
        "Predicted: ('Administration', 'Budget & Financial', 'Buildings & Facilities', 'Congressional Relations', 'Department Security', 'Inspector General', 'Strategic & Budget Planning')\n",
        "Actual: ['Administration', 'Afghanistan & Pakistan', 'Africa', 'Budget & Financial', 'Buildings & Facilities', 'Commercial & Economic Diplomacy', 'Commercial Advocacy', 'East Asia & Pacific', 'Energy', 'Europe & Eurasia', 'External Relations', 'Foreign Trade', \"Int'l Information Programs\", 'Internal Government', 'Middle East & North Africa', 'Oceans & Environment', 'Public Affairs', 'Public-Private Partnerships', 'Science & Tech Policy', 'South & Central Asia', 'Western Hemisphere']\n",
        "\n",
        "Predicted: ('Public Affairs', 'Public Diplomacy', 'Youth Issues')\n",
        "Actual: ['Afghanistan & Pakistan', 'Africa', 'Crisis Management', 'Crisis Prevention & Response', 'Equipping our People', 'Global Health', 'Health & HIV/AIDS', 'Human Resources', 'Middle East & North Africa', 'QDDR', 'South & Central Asia']\n",
        "\n",
        "Predicted: ('records management',)\n",
        "Actual: ['Administration', 'Africa', 'Anticorruption', 'Assistance Resources', 'Budget & Financial', 'Commercial & Economic Diplomacy', 'Commercial Advocacy', 'East Asia & Pacific', 'Economic Conditions', 'Equipping our People', 'Europe & Eurasia', 'Finance & Monetary', 'Food Security', 'Foreign Trade', 'Intellectual Property', 'Internal Government', 'Investment', 'Middle East & North Africa', \"Other Int'l Organization\", 'QDDR', 'Sanctions', 'Science & Tech Policy', 'South & Central Asia', 'Western Hemisphere', 'Whole of Government']\n",
        "\n",
        "Predicted: ('Public Affairs', 'Public Diplomacy', 'Youth Issues')\n",
        "Actual: ['Education & Exchanges', 'Principal Support', 'Protocol', 'Public-Private Partnerships', 'Public-Private Partnerships', 'Strategic & Budget Planning']\n",
        "\n",
        "Predicted: ('Administration', 'Budget & Financial', 'Buildings & Facilities', 'Department Security', 'Equipping our People', 'Strategic & Budget Planning')\n",
        "Actual: ['Administration', 'Department Security', 'Equipping our People', 'Information Technology']\n",
        "\n",
        "Predicted: ('Public Affairs', 'Public Diplomacy', 'Youth Issues')\n",
        "Actual: ['Administration', 'Africa', 'Anticorruption', 'Assistance Resources', 'Conflict & Stabilization', 'Crisis Management', 'Department Security', 'East Asia & Pacific', 'Equipping our People', 'External Relations', 'Human Rights & Democracy', 'Internal Government', 'Middle East & North Africa', 'QDDR', 'Religious Freedom & Discrimination', 'South & Central Asia', 'Western Hemisphere']\n",
        "\n",
        "Predicted: ('Commercial Advocacy', 'East Asia & Pacific', 'Finance & Monetary', 'Foreign Trade', \"Int'l Information Programs\", 'Investment', 'Middle East & North Africa', \"Other Int'l Organization\", 'QDDR', 'Strategic & Budget Planning', 'Whole of Government')\n",
        "Actual: ['Afghanistan & Pakistan', 'Africa', 'Assistance Resources', 'Budget & Financial', 'Democratization', 'East Asia & Pacific', 'Economic Conditions', 'Europe & Eurasia', 'External Relations', 'Food Security', 'Global Health', 'Health & HIV/AIDS', 'Human Resources', 'Human Rights', 'Human Rights & Democracy', 'Internal Government', 'Middle East & North Africa', \"Other Int'l Organization\", 'Professional Dev. & Training', 'Public-Private Partnerships', 'QDDR', 'South & Central Asia', 'Strategic & Budget Planning', 'United Nations', 'Western Hemisphere', \"Women's Issues\", 'Youth Issues']\n",
        "\n",
        "Predicted: (\"Int'l Information Programs\", 'QDDR', 'Strategic & Budget Planning', \"Women's Issues\", 'Youth Issues')\n",
        "Actual: ['Budget & Financial', 'Civil Society', 'Democratization', 'Economic Conditions', 'Education & Exchanges', 'External Relations', 'Human Resources', 'Human Rights', \"Int'l Information Programs\", 'Internal Government', 'Principal Support', 'Professional Dev. & Training', 'Public Affairs', 'Public Diplomacy', 'Public-Private Partnerships', 'Technology', 'Whole of Government', \"Women's Issues\", 'Youth Issues']\n",
        "\n",
        "Predicted: ('Public Affairs', 'Public Diplomacy', 'Youth Issues')\n",
        "Actual: ['Afghanistan & Pakistan', 'Africa', 'Conflict & Stabilization', 'Counterterrorism', 'Democratization', 'East Asia & Pacific', 'Education & Exchanges', 'Europe & Eurasia', 'External Relations', 'Human Rights', 'Human Rights & Democracy', \"Int'l Information Programs\", 'Middle East & North Africa', 'Middle East Peace', 'Public Affairs', 'Public Diplomacy', 'Public-Private Partnerships', 'Religious Freedom & Discrimination', 'South & Central Asia', 'Western Hemisphere', \"Women's Issues\", 'Youth Issues']\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_text = np.array(['In Sudan, there are many small businesses and we need to support them with NGOs and public-private partnerships.',\n",
      "                        'In China, we have lots of new technology emerging. The USG should strategically plan around this',\n",
      "                        'The embassy in Argentina is working hard on trade issues.'])\n",
      "print classifier.predict(sample_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Africa', 'Congressional Relations', 'Middle East & North Africa'), ('Administration', 'Budget & Financial', 'Europe & Eurasia', 'Legal & Treaty Issues', 'Strategic & Budget Planning', 'Western Hemisphere', 'Whole of Government'), ('Crisis Prevention & Response', 'Europe & Eurasia', 'Human Rights', 'Legal & Treaty Issues', 'Middle East & North Africa', 'Strategic & Budget Planning', 'Western Hemisphere', \"Women's Issues\")]\n"
       ]
      }
     ],
     "prompt_number": 338
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}